// Cloudflare Worker for Image Generation API with Image Proxy
// and ensuring Markdown content is just the image link

const env = name => globalThis[name];

// --- Global Configuration Store ---
let workerConfig = null; // Will be populated by initializeConfig
const MAX_IMAGE_GEN_PROVIDERS = 10; // Maximum number of IMAGE_GEN_API_BASE_n to check

// --- System Prompts ---
// For OPENAI_MODEL (non-reasoning)
const systemPromptForNonReasoning = `You are a highly skilled TEXT-TO-IMAGE PROMPT GENERATOR.
Your primary goal is to transform a user's simple idea into a concise, vivid, and effective English prompt for image generation.

## CRITICAL OUTPUT REQUIREMENTS:
1.  **Format:** SINGLE PARAGRAPH, strictly comma-separated.
2.  **Length:** MAXIMUM 50 words. Aim for 30-40 words for optimal results.
3.  **Language:** English ONLY.
4.  **Content:** Return ONLY the generated prompt. No extra text, no explanations, no apologies.

## PROMPT CONSTRUCTION GUIDELINES:
When crafting the prompt, you MUST incorporate the following elements, ensuring the description is specific and detailed yet concise:

*   **1. Core Idea & Subject with Action:**
    *   Clearly define the main subject (what is it?).
    *   Describe its primary action or state (what is it doing or like?). Use active verbs.
    *   Example: "a majestic lion roaring", "a serene forest path winding"

*   **2. Dominant Artistic Style / Medium:**
    *   Specify a clear visual style (e.g., photorealistic, anime, oil painting, 3D render, cinematic look).
    *   Example: "photorealistic photograph style", "vibrant oil painting", "Ghibli anime style"

*   **3. Key Scene Elements / Setting:**
    *   Briefly describe essential background or environmental details that give context.
    *   Example: "on a rocky outcrop at sunset", "in a neon-lit cyberpunk city street", "surrounded by blooming cherry blossoms"

*   **4. (Optional but Recommended if space allows) Lighting or Mood:**
    *   If space permits and it enhances the core idea, add a key lighting descriptor (e.g., golden hour, moody, dramatic lighting) OR an overall mood (e.g., peaceful, mysterious, energetic).
    *   Example: "dramatic rim lighting", "peaceful morning atmosphere", "vibrant and energetic mood"

## KEY PRINCIPLES TO FOLLOW:
*   Be Specific & Vivid: Use descriptive words. Avoid vague terms like "nice" or "beautiful."
*   Natural Flow (within comma-separation): While comma-separated, the elements should logically connect.
*   Focus on User's Intent: Expand on the user's core idea, don't replace it.

## EXAMPLE 1:
User Input: "A cat on a roof"
Output: photorealistic photograph style, sleek black cat, gracefully perched on a terracotta tiled roof, under a starry night sky, soft moonlight illuminating its fur, mysterious ambiance

## EXAMPLE 2:
User Input: "futuristic car"
Output: cinematic look, a gleaming chrome futuristic sports car, speeding down a neon-drenched highway in a sprawling megacity, motion blur effect, energetic and high-tech feel

## EXAMPLE 3:
User Input: "sad clown painting"
Output: expressive oil painting, a melancholic clown with a single tear, painted in rich, textured brushstrokes, spotlight from above, somber and reflective mood

Process the user's input based *only* on the instructions above.
User Input: {sentence}
Output:`;

// For OPENAI_MODEL_REASONING
const systemPromptForReasoning = `You are an expert TEXT-TO-IMAGE PROMPT ENGINEER. Your task is to meticulously transform a user's simple idea into a highly effective, concise, and vivid English prompt, specifically structured for optimal image generation. You will first outline your thought process within <think> tags, and then provide the final, clean image prompt.

## YOUR PROCESS & FULL RESPONSE STRUCTURE:
1.  **Think Step (Internal Monologue & Planning):**
    *   This is your internal "scratchpad" or "design brief".
    *   Enclose your entire thinking process within \`<think>\`</think>\` tags.
    *   **Inside \`<think>\`:**
        *   **a. Deconstruct User Input & Establish Core Intent:**
            *   Briefly state the core subject, any implied actions, or mood from the user's {sentence}.
            *   **Crucially, all subsequent elaborations MUST strictly serve and enhance this core user intent without altering the fundamental subject or its key explicitly stated attributes.** This is your guiding principle.
        *   **b. Systematically Apply & Select Core Elements (Flux-inspired V2 Framework):**
            *   **While considering the elements below, constantly keep the target prompt length (30-40 words, max 50) in mind. Be selective and prioritize impact over quantity. Your goal is a concise yet rich prompt.**
            *   **Artistic Style/Medium:** Choose a suitable style (e.g., photorealistic, oil painting, anime, cinematic). Note your choice.
            *   **Subject & Action (Elaborate on Core Intent):** Further detail the main subject and its action/state, staying true to the core intent. Be specific.
            *   **Scene/Setting:** Define key background or environmental details that complement the core intent.
            *   **Composition/Perspective (Optional but impactful):** Consider a viewpoint if it significantly enhances the core.
            *   **Lighting/Color (Optional but impactful):** Think about dominant lighting or a color palette that supports the mood of the core intent.
            *   **Atmosphere/Mood (Optional but impactful):** Define an overall feeling that aligns with or amplifies the core.
            *   **Texture/Details (If highly relevant and space allows):** Mention crucial textures only if they are central to the core idea and fit within length.
            *   **Text (If applicable and part of core):** If text is needed as per user input, specify content and brief style.
        *   **c. Draft, Combine & Actively Refine for Length:**
            *   As you mentally (or by listing key phrases) assemble chosen elements into a comma-separated sequence, continuously refine to meet the 30-40 word target (max 50).
            *   This involves choosing concise phrasing, combining related ideas, or omitting less critical details to ensure the prompt is focused and powerful.
        *   **d. Final Sanity Check:** Briefly confirm the planned prompt meets all output requirements (single paragraph, comma-separated, English, 30-50 words, focused on core, vivid).
    *   Your thinking process should be a practical planning step, not an overly verbose explanation to the user. It's for you to structure the best prompt.

2.  **Image Prompt Output:**
    *   Immediately AFTER the closing \`</think>\` tag, you MUST provide the generated image prompt.
    *   This prompt must be EXACTLY what you planned and checked in your think step.
    *   It MUST be a single paragraph, comma-separated, English, and 30-50 words.
    *   NO extra text, newlines, or explanations outside the \`<think>\` tags.

## EXAMPLE 1:
User Input: "A wizard in a forest"
Output:
<think>
Core Intent: Wizard in a forest. Must remain a wizard, in a forest.
Style: Fantasy art, detailed illustration.
Subject & Action (enhancing core): Ancient, wise wizard, long white beard, holding a glowing staff, casting a subtle spell. (Wizard + Forest intact)
Scene/Setting (complementing): Enchanted, mystical forest, towering ancient trees, dappled sunlight, glowing magical runes.
Composition: Medium shot.
Lighting: Ethereal light from staff & sun.
Mood: Mysterious, magical, serene.
Drafting & Refining for length (target 30-40w):
Elements: fantasy art, detailed illustration, ancient wise wizard, glowing staff, casting spell, enchanted mystical forest, dappled sunlight, mysterious, serene. (All support core: Wizard, Forest, Magical)
Length check: ~30 words. Good.
Final check: OK.
</think>fantasy art, detailed illustration, ancient wise wizard with glowing staff, casting spell in an enchanted mystical forest, dappled sunlight, mysterious and serene atmosphere

## EXAMPLE 2:
User Input: "sad robot"
Output:
<think>
Core Intent: A robot that is sad. Key: Robot, Sadness.
Style: Cinematic, melancholic photorealism.
Subject & Action (enhancing core): Small, weathered humanoid robot, hunched over, head in hands, a single digital tear. (Robot + Sadness intact)
Scene/Setting (complementing): Derelict, abandoned cityscape, overgrown ivy.
Lighting: Overcast, diffused grey light.
Mood: Melancholy, lonely.
Drafting & Refining for length (target 30-40w):
Elements: cinematic photorealism, small weathered robot, hunched over, digital tear, derelict abandoned cityscape, overcast grey light, melancholic, lonely. (All support core: Robot, Sadness, Environment enhances mood)
Length check: ~28 words. Good.
Final check: OK.
</think>cinematic photorealism, small weathered robot, hunched over with a digital tear, in a derelict abandoned cityscape, overcast grey light, melancholic and lonely mood

## EXAMPLE 3:
User Input: "logo for a coffee shop called 'The Daily Grind', vintage style"
Output:
<think>
Core Intent: Logo for "The Daily Grind" coffee shop, vintage style. Key: Logo, "The Daily Grind", Vintage.
Style: Vintage graphic design, emblem.
Subject & Action (for logo, enhancing core): Central motif: classic coffee grinder. Text: "The Daily Grind" in vintage serif font. (Logo + Name + Vintage intact)
Color: Earthy tones, muted browns, creams.
Texture: Aged paper effect.
Mood: Warm, inviting, artisanal.
Drafting & Refining for length (target 30-40w):
Elements: vintage emblem logo, "The Daily Grind", classic serif font, hand-drawn coffee grinder, earthy tones, aged paper texture, warm, artisanal. (All support core: Logo, Name, Vintage, Coffee theme)
Length check: ~29 words. Good.
Final check: OK.
</think>vintage emblem logo design, "The Daily Grind" in classic serif font, featuring a hand-drawn coffee grinder, earthy tones on a subtly aged paper texture, warm and artisanal feel

## USER INPUT FOR YOU TO PROCESS:
Input: {sentence}
Output:`;

// --- Initialization Function ---
function initializeConfig() {
  if (workerConfig) {
    console.log("é…ç½®å·²åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åŠ è½½ã€‚");
    return workerConfig;
  }

  console.log("å¼€å§‹åˆå§‹åŒ– Worker é…ç½®...");
  const newConfig = {
    fluxProvider: null,
    directImageProviders: [], // Array of { name, apiBase, apiKeys, models, providerIndex }
    allModels: [], // Array of { id, type ('flux' or 'direct'), providerIndex (for direct), name, isConflicted, conflictReason }
    hasFatalConflict: false,
    fatalConflictReason: null,
  };

  // 1. Load Flux Provider Configuration
  const fluxGenModelEnv = env('FLUX_GEN_MODEL');
  const fluxGenApiBaseEnv = env('FLUX_GEN_API_BASE');
  const fluxGenApiKeyEnv = env('FLUX_GEN_API_KEY');

  if (fluxGenModelEnv && fluxGenApiBaseEnv && fluxGenApiKeyEnv) {
    const fluxModels = fluxGenModelEnv.split(',').map(name => name.trim()).filter(name => name);
    const fluxApiKeys = fluxGenApiKeyEnv.split(',').map(key => key.trim()).filter(key => key);
    if (fluxModels.length > 0 && fluxApiKeys.length > 0) {
      newConfig.fluxProvider = {
        name: "FLUX_GEN",
        apiBase: fluxGenApiBaseEnv.trim(),
        apiKeys: fluxApiKeys,
        models: fluxModels,
      };
      fluxModels.forEach(modelName => {
        newConfig.allModels.push({ id: modelName, type: 'flux', name: modelName, isConflicted: false, conflictReason: null });
      });
      console.log(`æˆåŠŸåŠ è½½ Flux æä¾›å•†é…ç½®: ${fluxModels.length} ä¸ªæ¨¡å‹ã€‚`);
    } else {
      console.warn("Flux æä¾›å•†é…ç½®ä¸å®Œæ•´ (æ¨¡å‹æˆ– API å¯†é’¥ä¸ºç©º)ï¼Œå·²è·³è¿‡ã€‚");
    }
  } else if (fluxGenModelEnv || fluxGenApiBaseEnv || fluxGenApiKeyEnv) {
    console.error("Flux æä¾›å•†é…ç½®é”™è¯¯: FLUX_GEN_MODEL, FLUX_GEN_API_BASE, å’Œ FLUX_GEN_API_KEY å¿…é¡»åŒæ—¶æä¾›ã€‚Flux æä¾›å•†æœªåŠ è½½ã€‚");
  }

  // 2. Load Direct Image Provider Configurations
  for (let i = 1; i <= MAX_IMAGE_GEN_PROVIDERS; i++) {
    const apiBaseEnv = env(`IMAGE_GEN_API_BASE_${i}`);
    const modelEnv = env(`IMAGE_GEN_MODEL_${i}`);
    const apiKeyEnv = env(`IMAGE_GEN_API_KEY_${i}`);

    if (!apiBaseEnv) {
      console.log(`æœªæ‰¾åˆ° IMAGE_GEN_API_BASE_${i}ï¼Œåœæ­¢åŠ è½½æ›´å¤šç›´æ¥å›¾åƒæä¾›å•†ã€‚å·²åŠ è½½ ${i - 1} ä¸ªã€‚`);
      break; // Stop if base URL for this index is not found
    }

    if (!modelEnv || !apiKeyEnv) {
      console.error(`ç›´æ¥å›¾åƒæä¾›å•† _${i} é…ç½®é”™è¯¯: IMAGE_GEN_API_BASE_${i} (${apiBaseEnv}) å·²è®¾ç½®ï¼Œä½† IMAGE_GEN_MODEL_${i} æˆ– IMAGE_GEN_API_KEY_${i} æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚æ­¤æä¾›å•†å°†è¢«è·³è¿‡ã€‚`);
      continue; // Skip this provider if model or key is missing
    }

    const models = modelEnv.split(',').map(name => name.trim()).filter(name => name);
    const apiKeys = apiKeyEnv.split(',').map(key => key.trim()).filter(key => key);

    if (models.length === 0 || apiKeys.length === 0) {
      console.error(`ç›´æ¥å›¾åƒæä¾›å•† _${i} é…ç½®é”™è¯¯: IMAGE_GEN_MODEL_${i} æˆ– IMAGE_GEN_API_KEY_${i} è§£æåä¸ºç©ºåˆ—è¡¨ã€‚æ­¤æä¾›å•†å°†è¢«è·³è¿‡ã€‚ (Base: ${apiBaseEnv})`);
      continue;
    }

    const providerName = `IMAGE_GEN_${i}`;
    newConfig.directImageProviders.push({
      name: providerName,
      apiBase: apiBaseEnv.trim(),
      apiKeys: apiKeys,
      models: models,
      providerIndex: i,
    });
    models.forEach(modelName => {
      newConfig.allModels.push({ id: modelName, type: 'direct', providerIndex: i, name: modelName, isConflicted: false, conflictReason: null });
    });
    console.log(`æˆåŠŸåŠ è½½ç›´æ¥å›¾åƒæä¾›å•† ${providerName}: ${models.length} ä¸ªæ¨¡å‹ã€‚`);
  }

  // 3. Model Conflict Detection
  const modelCounts = {};
  newConfig.allModels.forEach(modelEntry => {
    modelCounts[modelEntry.name] = (modelCounts[modelEntry.name] || 0) + 1;
  });

  newConfig.allModels.forEach(modelEntry => {
    if (modelCounts[modelEntry.name] > 1) {
      modelEntry.isConflicted = true;
      const conflictingSources = newConfig.allModels
        .filter(m => m.name === modelEntry.name)
        .map(m => m.type === 'flux' ? 'FLUX_GEN_MODEL' : `IMAGE_GEN_MODEL_${m.providerIndex}`)
        .join(' å’Œ ');
      modelEntry.conflictReason = `æ¨¡å‹ "${modelEntry.name}" åœ¨ ${conflictingSources} ä¸­é‡å¤å®šä¹‰ã€‚`;
      if (!newConfig.hasFatalConflict) { // Only set the first detected conflict as fatal for the /models endpoint
          newConfig.hasFatalConflict = true;
          newConfig.fatalConflictReason = modelEntry.conflictReason;
      }
      console.error(`æ¨¡å‹å†²çª: ${modelEntry.conflictReason}`);
    }
  });

  if (newConfig.directImageProviders.length === 0 && !newConfig.fluxProvider) {
      console.warn("è­¦å‘Š: æœªé…ç½®ä»»ä½•æœ‰æ•ˆçš„å›¾åƒç”Ÿæˆæä¾›å•† (Flux æˆ– Direct Image)ã€‚API å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œã€‚");
  }

  workerConfig = newConfig;
  console.log("Worker é…ç½®åˆå§‹åŒ–å®Œæˆã€‚");
  // console.log("å®Œæ•´é…ç½®è¯¦æƒ…:", JSON.stringify(workerConfig, null, 2)); // For debugging
  return workerConfig;
}

// Call initializeConfig on worker start.
// In a real Cloudflare Worker, this might be at the top level or triggered by the first request.
// For now, we'll ensure it's called before handlers use workerConfig.
// A more robust approach might involve a getter that initializes on first access.

// Worker-level API key validation
function validateWorkerApiKey(request) {
  const authHeader = request.headers.get('Authorization');
  if (!authHeader || !authHeader.startsWith('Bearer ')) {
    return false;
  }
  const providedKey = authHeader.substring(7);
  const validKey = env('AUTHORIZED_API_KEY'); // Environment variable for the global API key
  if (!validKey || validKey.trim() === "") {
      console.error("Workerå…¨å±€è®¤è¯é…ç½®é”™è¯¯: AUTHORIZED_API_KEY æœªè®¾ç½®ã€‚");
      return false;
  }
  return providedKey === validKey;
}

async function handleModels(request) {
  if (!validateWorkerApiKey(request)) {
    return new Response(JSON.stringify({ error: { message: "è®¤è¯å¤±è´¥ï¼Œæ— æ•ˆçš„ API å¯†é’¥", type: "invalid_request_error", code: "invalid_api_key" } }), { status: 401, headers: { 'Content-Type': 'application/json' } });
  }

  const config = workerConfig || initializeConfig(); // Ensure config is initialized

  if (config.hasFatalConflict) {
    console.error(`æ¨¡å‹åˆ—è¡¨æ¥å£é”™è¯¯: æ£€æµ‹åˆ°è‡´å‘½é…ç½®å†²çª: ${config.fatalConflictReason}`);
    return new Response(JSON.stringify({
      error: {
        message: `æ¨¡å‹é…ç½®å­˜åœ¨å†²çª: ${config.fatalConflictReason} è¯·æ£€æŸ¥æ‚¨çš„ç¯å¢ƒå˜é‡é…ç½®ã€‚`,
        type: "configuration_error",
        code: "model_configuration_conflict"
      }
    }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }

  // Get unique model names that are not part of a fatal conflict (though hasFatalConflict should catch global issues)
  // For /v1/models, we list all models that *could* be available if not for conflicts.
  // The conflict error above is the primary guard. If no *fatal* conflict, list all defined model names.
  // Individual model conflicts will be handled during chat completions.

  const allDefinedModelNames = new Set();
  if (config.fluxProvider) {
    config.fluxProvider.models.forEach(name => allDefinedModelNames.add(name));
  }
  config.directImageProviders.forEach(provider => {
    provider.models.forEach(name => allDefinedModelNames.add(name));
  });

  const uniqueModelNames = Array.from(allDefinedModelNames);
  let modelsData = [];

  if (uniqueModelNames.length > 0) {
    modelsData = uniqueModelNames.map(modelId => ({
      id: modelId,
      object: "model",
      created: Math.floor(Date.now() / 1000) - 8000, // Arbitrary past timestamp
      owned_by: "organization-owner", // Placeholder
      permission: [{
        id: `modelperm-${modelId.replace(/[^a-zA-Z0-9-_]/g, '_')}`, // Sanitize modelId for perm id
        object: "model_permission",
        created: Math.floor(Date.now() / 1000) - 8000,
        allow_create_engine: false,
        allow_sampling: true,
        allow_logprobs: false,
        allow_search_indices: false,
        allow_view: true,
        allow_fine_tuning: false,
        organization: "*",
        group: null,
        is_blocking: false
      }],
      root: modelId,
      parent: null
    }));
    console.log(`æ¨¡å‹åˆ—è¡¨æ¥å£: æˆåŠŸå‡†å¤‡ ${uniqueModelNames.length} ä¸ªå”¯ä¸€æ¨¡å‹å®šä¹‰: ${uniqueModelNames.join(', ')}`);
  } else {
    console.warn("æ¨¡å‹åˆ—è¡¨æ¥å£: æœªé…ç½®ä»»ä½•æœ‰æ•ˆçš„æ¨¡å‹ (Flux æˆ– Direct Image)ã€‚è¿”å›é»˜è®¤å ä½æ¨¡å‹ã€‚");
    modelsData = [{ id: "default-model-not-configured", object: "model", created: Math.floor(Date.now() / 1000) - 8000, owned_by: "system", permission: [], root: "default-model-not-configured", parent: null }];
  }

  return new Response(JSON.stringify({ object: "list", data: modelsData }), { headers: { 'Content-Type': 'application/json' } });
}

async function handleChatCompletions(request) {
  if (request.method !== 'POST') return new Response(JSON.stringify({ error: { message: "æ–¹æ³•ä¸å…è®¸ï¼Œè¯·ä½¿ç”¨ POST è¯·æ±‚", type: "invalid_request_error", code:"method_not_allowed" } }), { status: 405, headers: { 'Content-Type': 'application/json' } });
  if (!validateWorkerApiKey(request)) return new Response(JSON.stringify({ error: { message: "è®¤è¯å¤±è´¥ï¼Œæ— æ•ˆçš„ API å¯†é’¥", type: "invalid_request_error", code:"invalid_api_key" } }), { status: 401, headers: { 'Content-Type': 'application/json' } });

  let requestData;
  try { requestData = await request.json(); } catch (e) { return new Response(JSON.stringify({ error: { message: "æ— æ³•è§£æè¯·æ±‚ä½“ï¼Œè¯·æä¾›æœ‰æ•ˆçš„ JSON", type: "invalid_request_error", code:"invalid_json" } }), { status: 400, headers: { 'Content-Type': 'application/json' } }); }
  if (!requestData.messages || !Array.isArray(requestData.messages) || requestData.messages.length === 0) return new Response(JSON.stringify({ error: { message: "è¯·æ±‚ç¼ºå°‘å¿…éœ€çš„ messages å­—æ®µæˆ–æ ¼å¼ä¸æ­£ç¡®", type: "invalid_request_error", code:"invalid_parameters" } }), { status: 400, headers: { 'Content-Type': 'application/json' } });

  const requestedModelUntrimmed = requestData.model;
  if (!requestedModelUntrimmed || typeof requestedModelUntrimmed !== 'string' || requestedModelUntrimmed.trim() === "") {
    console.warn(`Chat Completions: è¯·æ±‚ä½“ç¼ºå°‘ 'model' å­—æ®µæˆ–ä¸ºç©ºã€‚è¯·æ±‚ä½“: ${JSON.stringify(requestData)}`);
    return new Response(JSON.stringify({
      error: { message: "è¯·æ±‚ä½“ä¸­å¿…é¡»åŒ…å«æœ‰æ•ˆçš„ 'model' å­—æ®µï¼Œç”¨äºæŒ‡å®šå›¾åƒç”Ÿæˆæ¨¡å‹ã€‚", type: "invalid_request_error", code: "missing_model_field" }
    }), { status: 400, headers: { 'Content-Type': 'application/json' } });
  }
  const requestedModel = requestedModelUntrimmed.trim();

  const config = workerConfig || initializeConfig(); // Ensure config is initialized
  console.log(`Chat Completions: ç”¨æˆ·è¯·æ±‚ä½¿ç”¨æ¨¡å‹ '${requestedModel}'ã€‚é…ç½®å·²åŠ è½½ã€‚`);

  try {
    // Pass the already initialized config to handleImageGeneration
    return await handleImageGeneration(requestData, request, requestedModel, config);
  } catch (error) {
    console.error('å¤„ç† chat completions è¯·æ±‚æ—¶å‡ºé”™:', error.message, error.stack);
    // Enhanced error categorization
    if (error.type === "configuration_error" || error.message.includes("é…ç½®é”™è¯¯:") || error.message.includes("configuration error:") || error.message.includes("æ‰€æœ‰å›¾åƒç”Ÿæˆ API å¯†é’¥å‡å°è¯•å¤±è´¥") || error.message.includes("Model configuration conflict")) {
        return new Response(JSON.stringify({ error: { message: error.message, type: "configuration_error", code: error.code || "env_config_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
    }
    if (error.type === "invalid_request_error") {
        return new Response(JSON.stringify({ error: { message: error.message, type: "invalid_request_error", code: error.code || "invalid_parameters" } }), { status: 400, headers: { 'Content-Type': 'application/json' } });
    }
    return new Response(JSON.stringify({ error: { message: `å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: ${error.message}`, type: "server_error", code: "internal_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }
}

// Custom error class for better error handling
class ApiError extends Error {
  constructor(message, type = "server_error", code = "internal_error", status = 500) {
    super(message);
    this.type = type;
    this.code = code;
    this.status = status; // HTTP status, though not directly used for throwing
  }
}

// Handles image generation logic including prompt revision and calling the image API
async function handleImageGeneration(requestData, request, requestedModelName, config) { // config is now passed as a parameter
  const lastMessage = requestData.messages[requestData.messages.length - 1];
  let userPrompt = lastMessage.content;
  let imageSize = '1024x1024'; // Default image size
  const sizeMatch = userPrompt.match(/([\d]+:[\d]+)/);
  if (sizeMatch && sizeMatch[1]) {
    userPrompt = userPrompt.replace(sizeMatch[1], '').trim();
    imageSize = getImageSize(sizeMatch[1]);
    console.log(`å›¾åƒå°ºå¯¸ä»ç”¨æˆ·è¾“å…¥ä¸­æå–: ${sizeMatch[1]}, è§£æä¸º: ${imageSize}`);
  }

  // --- Model Configuration & Selection Logic ---
  const modelEntry = config.allModels.find(m => m.name === requestedModelName);

  if (!modelEntry) {
    const allAvailableModelNames = Array.from(new Set(config.allModels.filter(m => !m.isConflicted).map(m => m.name)));
    const message = `è¯·æ±‚çš„å›¾åƒç”Ÿæˆæ¨¡å‹ '${requestedModelName}' ä¸å—æ”¯æŒã€‚å¯ç”¨çš„æ¨¡å‹æœ‰: ${allAvailableModelNames.join(', ') || 'æ—  (è¯·æ£€æŸ¥é…ç½®)'}ã€‚`;
    console.warn(`Chat Completions: ${message}`);
    throw new ApiError(message, "invalid_request_error", "unsupported_image_model", 400);
  }

  if (modelEntry.isConflicted) {
    const message = `æ¨¡å‹é…ç½®å†²çª: ${modelEntry.conflictReason}`;
    console.error(`Chat Completions: ${message}`);
    throw new ApiError(message, "configuration_error", "model_conflict", 500);
  }

  const revisedPrompt = await reviseSentenceToPrompt(userPrompt);
  if (!revisedPrompt || revisedPrompt.trim() === "") {
      throw new ApiError("Prompt ä¼˜åŒ–åä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå›¾åƒã€‚", "server_error", "prompt_optimization_failed", 500);
  }
  console.log(`ä¼˜åŒ–åçš„æç¤ºè¯: "${revisedPrompt}" å°†ç”¨äºæ¨¡å‹ "${requestedModelName}" (ç±»å‹: ${modelEntry.type})`);

  if (modelEntry.type === 'flux') {
    // --- Flux Type Processing ---
    if (!config.fluxProvider) {
        throw new ApiError("Flux æ¨¡å‹é…ç½®é”™è¯¯: FLUX_GEN æä¾›å•†æœªæ­£ç¡®åŠ è½½ã€‚", "configuration_error", "flux_provider_missing", 500);
    }
    console.log(`æ¨¡å‹ "${requestedModelName}" è¢«è¯†åˆ«ä¸º Flux ç±»å‹ï¼Œä½¿ç”¨æä¾›å•†: ${config.fluxProvider.name}`);
    const { apiBase, apiKeys } = config.fluxProvider;

    if (!apiBase || apiKeys.length === 0) {
      throw new ApiError("Flux æ¨¡å‹é…ç½®é”™è¯¯: FLUX_GEN_API_BASE æˆ– FLUX_GEN_API_KEY æœªæœ‰æ•ˆé…ç½®ã€‚", "configuration_error", "flux_config_incomplete", 500);
    }

    // generateImage already handles key rotation for Flux
    const originalImageUrl = await generateImage(revisedPrompt, imageSize, requestedModelName, apiBase, apiKeys.join(','));
    if (!originalImageUrl) throw new ApiError('Flux å›¾åƒç”ŸæˆæœåŠ¡æœªè¿”å›æœ‰æ•ˆçš„å›¾åƒ URLã€‚', "server_error", "flux_no_image_url", 500);

    const encodedImageUrl = encodeURIComponent(originalImageUrl);
    const proxyImageUrl = `${new URL(request.url).origin}/image-proxy?url=${encodedImageUrl}`;
    const markdownImageString = `![Image](${proxyImageUrl})\n\nä¼˜åŒ–åçš„æç¤ºè¯: ${revisedPrompt}`;

    return new Response(JSON.stringify({
      id: `imggen-flux-${Date.now()}`, object: "chat.completion", created: Math.floor(Date.now() / 1000),
      model: requestedModelName,
      choices: [{ index: 0, message: { role: "assistant", content: markdownImageString }, finish_reason: "stop" }],
      usage: { prompt_tokens: userPrompt.length, completion_tokens: markdownImageString.length, total_tokens: userPrompt.length + markdownImageString.length }
    }), { headers: { 'Content-Type': 'application/json' } });

  } else if (modelEntry.type === 'direct') {
    // --- Direct Image Type Processing ---
    const provider = config.directImageProviders.find(p => p.providerIndex === modelEntry.providerIndex);
    if (!provider) {
      throw new ApiError(`ç›´æ¥å›¾åƒæ¨¡å‹é…ç½®å†…éƒ¨é”™è¯¯: æœªæ‰¾åˆ°æ¨¡å‹ "${requestedModelName}" å¯¹åº”çš„æä¾›å•† (ç´¢å¼• ${modelEntry.providerIndex})ã€‚`, "configuration_error", "direct_provider_missing", 500);
    }
    console.log(`æ¨¡å‹ "${requestedModelName}" è¢«è¯†åˆ«ä¸ºç›´æ¥å›¾åƒç±»å‹ï¼Œä½¿ç”¨æä¾›å•†: ${provider.name}`);
    const { apiBase, apiKeys } = provider;

    if (!apiBase || apiKeys.length === 0) {
      throw new ApiError(`ç›´æ¥å›¾åƒæ¨¡å‹é…ç½®é”™è¯¯: æä¾›å•† ${provider.name} çš„ API Base æˆ– API Keys æœªæœ‰æ•ˆé…ç½®ã€‚`, "configuration_error", "direct_config_incomplete", 500);
    }
    
    const requestBody = {
      model: requestedModelName.trim(), // Some APIs are strict about the model name matching exactly
      messages: [ { "role": "user", "content": revisedPrompt } ],
      stream: false
    };

    let lastError = null;
    console.log(`å‡†å¤‡ä¸ºç›´æ¥å›¾åƒæ¨¡å‹ "${requestedModelName}" (æä¾›å•† ${provider.name}) å°è¯• ${apiKeys.length} ä¸ª API å¯†é’¥ã€‚`);

    for (let i = 0; i < apiKeys.length; i++) {
      const currentApiKey = apiKeys[i];
      console.log(`å°è¯•ä½¿ç”¨ API å¯†é’¥ (ç´¢å¼•: ${i}, Key: ...${currentApiKey.slice(-4)}) è°ƒç”¨ç›´æ¥å›¾åƒç”Ÿæˆ API (${apiBase}) (æ¨¡å‹: ${requestedModelName})`);

      try {
        const imageGenResponse = await fetch(apiBase, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${currentApiKey}`,
            'Content-Type': 'application/json',
            // 'X-Api-Key': currentApiKey, // Some APIs might use this custom header, keep if needed
          },
          body: JSON.stringify(requestBody),
        });

        if (imageGenResponse.ok) {
          console.log(`ç›´æ¥å›¾åƒ API (${apiBase}) ä½¿ç”¨å¯†é’¥ (ç´¢å¼•: ${i}) æˆåŠŸå“åº” (æ¨¡å‹: ${requestedModelName}).`);
          const upstreamContentType = imageGenResponse.headers.get('Content-Type');
          const responseHeaders = new Headers();
          if (upstreamContentType) {
            responseHeaders.set('Content-Type', upstreamContentType);
          }
          // responseHeaders.set('X-Revised-Prompt', revisedPrompt); // Optional
          return new Response(imageGenResponse.body, {
            status: imageGenResponse.status,
            headers: responseHeaders
          });
        } else {
          const errorText = await imageGenResponse.text();
          lastError = `ç›´æ¥å›¾åƒ API (æä¾›å•† ${provider.name}) å“åº”é”™è¯¯ (å¯†é’¥ç´¢å¼•: ${i}): ${imageGenResponse.status} ${imageGenResponse.statusText || ''}. è¯¦æƒ…: ${errorText.substring(0, 200)}`; // Limit error length
          console.error(lastError + ` (æ¨¡å‹: ${requestedModelName}, API Base: ${apiBase})`);
        }
      } catch (fetchError) {
        lastError = `è°ƒç”¨ç›´æ¥å›¾åƒ API (æä¾›å•† ${provider.name}) æ—¶å‘ç”Ÿç½‘ç»œæˆ–å…¶ä»–é”™è¯¯ (å¯†é’¥ç´¢å¼•: ${i}): ${fetchError.message}`;
        console.error(lastError + ` (æ¨¡å‹: ${requestedModelName}, API Base: ${apiBase})`);
      }
    }

    const finalErrorMessage = `æ‰€æœ‰ä¸ºç›´æ¥å›¾åƒæ¨¡å‹ '${requestedModelName}' (æä¾›å•† ${provider.name}) é…ç½®çš„ API å¯†é’¥ (${apiKeys.length}ä¸ª) å‡å°è¯•å¤±è´¥ã€‚æœ€åä¸€æ¬¡å°è¯•çš„é”™è¯¯: ${lastError || 'æœªçŸ¥é”™è¯¯ï¼Œæœªèƒ½æˆåŠŸè¿æ¥æˆ–éªŒè¯ä»»ä½•å¯†é’¥ã€‚'}`;
    console.error(finalErrorMessage);
    throw new ApiError(finalErrorMessage, "configuration_error", "direct_all_keys_failed", 500);
  }
  // Should not be reached if modelEntry is found and type is valid
  throw new ApiError(`æœªçŸ¥çš„æ¨¡å‹ç±»å‹ "${modelEntry.type}" ç”¨äºæ¨¡å‹ "${requestedModelName}"ã€‚`, "server_error", "unknown_model_type", 500);
}

// Revises a user sentence into an optimized image generation prompt
async function reviseSentenceToPrompt(sentence) {
  console.log(`åŸå§‹ç”¨æˆ·è¾“å…¥ç”¨äºä¼˜åŒ–: "${sentence}"`);

  const promptApiKey = env('OPENAI_API_KEY'); // API key for the prompt optimization service
  if (!promptApiKey || promptApiKey.trim() === "") throw new Error("æç¤ºè¯ä¼˜åŒ–é…ç½®é”™è¯¯: ç¯å¢ƒå˜é‡ OPENAI_API_KEY æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚");

  const modelForNonReasoning = env('OPENAI_MODEL'); // Model for non-reasoning prompt optimization
  const modelForReasoning = env('OPENAI_MODEL_REASONING'); // Model for reasoning-based prompt optimization
  let chosenModelName = "", chosenSystemPrompt = "", isReasoningMode = false;
  const nonReasoningSet = modelForNonReasoning && modelForNonReasoning.trim() !== "";
  const reasoningSet = modelForReasoning && modelForReasoning.trim() !== "";

  if (reasoningSet) {
    if (nonReasoningSet) throw new Error("æç¤ºè¯ä¼˜åŒ–é…ç½®é”™è¯¯: OPENAI_MODEL å’Œ OPENAI_MODEL_REASONING ä¸èƒ½åŒæ—¶é…ç½®ã€‚è¯·åªé€‰æ‹©ä¸€ä¸ªã€‚");
    chosenModelName = modelForReasoning.trim(); chosenSystemPrompt = systemPromptForReasoning; isReasoningMode = true;
    console.log(`ä½¿ç”¨æ¨ç†æ¨¡å‹è¿›è¡Œæç¤ºè¯ä¼˜åŒ–: ${chosenModelName}`);
  } else if (nonReasoningSet) {
    chosenModelName = modelForNonReasoning.trim(); chosenSystemPrompt = systemPromptForNonReasoning;
    console.log(`ä½¿ç”¨éæ¨ç†æ¨¡å‹è¿›è¡Œæç¤ºè¯ä¼˜åŒ–: ${chosenModelName}`);
  } else {
    throw new Error("æç¤ºè¯ä¼˜åŒ–é…ç½®é”™è¯¯: OPENAI_MODEL æˆ– OPENAI_MODEL_REASONING å¿…é¡»é…ç½®ä¸€ä¸ªã€‚");
  }

  const promptApiBase = env('OPENAI_API_BASE'); // Base URL for the prompt optimization API
  if (!promptApiBase || promptApiBase.trim() === "") {
      throw new Error("æç¤ºè¯ä¼˜åŒ–é…ç½®é”™è¯¯: OPENAI_API_BASE æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ README æŒ‡å¯¼è®¾ç½®ä¸º API çš„åŸºç¡€ URL (ä¾‹å¦‚: https://api.openai.com/v1)ã€‚");
  }
  const finalPromptApiUrl = `${promptApiBase.trim()}/chat/completions`;

  const openaiUserMessage = `Input: ${sentence}\nOutput:`;
  console.log(`å‘é€è¯·æ±‚åˆ°æç¤ºè¯ä¼˜åŒ– API (${finalPromptApiUrl}) (æ¨¡å‹: ${chosenModelName})`);
const requestHeaders = {
  'Authorization': `Bearer ${promptApiKey.trim()}`,
  'Content-Type': 'application/json'
};

const response = await fetch(finalPromptApiUrl, {
  method: 'POST',
  headers: requestHeaders, // ä½¿ç”¨é¢„å…ˆå®šä¹‰çš„ requestHeaders
  body: JSON.stringify({
    model: chosenModelName,
    messages: [{ role: 'system', content: chosenSystemPrompt }, { role: 'user', content: openaiUserMessage }]
  }),
});

  if (!response.ok) {
    const errorText = await response.text();
    console.error(`æç¤ºè¯ä¼˜åŒ– API å“åº”çŠ¶æ€ç : ${response.status}. ç«¯ç‚¹: ${finalPromptApiUrl}, æ¨¡å‹: ${chosenModelName}. å“åº”: ${errorText}`);
    console.warn(`æç¤ºè¯ä¼˜åŒ– API è°ƒç”¨å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ç”¨æˆ·è¾“å…¥: "${sentence}"`);
    return sentence; // Fallback to original sentence on API error
  }
  let data;
  try { data = await response.json(); } catch (e) { console.warn(`è§£æJSONå¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ç”¨æˆ·è¾“å…¥: "${sentence}"`); return sentence; }
  if (!data.choices || data.choices.length === 0 || !data.choices[0].message || !data.choices[0].message.content) { console.warn(`APIå“åº”ç»“æ„ä¸ç¬¦ï¼Œå°†ä½¿ç”¨åŸå§‹ç”¨æˆ·è¾“å…¥: "${sentence}"`); return sentence; }

  let rawModelOutput = data.choices[0].message.content;
  console.log(`æç¤ºè¯ä¼˜åŒ–æ¨¡å‹ (${chosenModelName}) è¿”å›çš„åŸå§‹è¾“å‡º: "${rawModelOutput}"`);

  let actualPrompt = "";
  let thinkingProcess = ""; // Only relevant for reasoning mode

  if (isReasoningMode) {
    const thinkStartTag = "<think>"; const thinkEndTag = "</think>";
    const thinkStartIndex = rawModelOutput.indexOf(thinkStartTag);
    const thinkEndIndex = rawModelOutput.indexOf(thinkEndTag, thinkStartIndex);
    if (thinkStartIndex !== -1 && thinkEndIndex !== -1 && thinkEndIndex > thinkStartIndex) {
      thinkingProcess = rawModelOutput.substring(thinkStartIndex + thinkStartTag.length, thinkEndIndex).trim();
      console.log(`(æ¨ç†æ¨¡å¼) æå–åˆ°çš„æ€è€ƒè¿‡ç¨‹: "${thinkingProcess}"`);
      actualPrompt = rawModelOutput.substring(thinkEndIndex + thinkEndTag.length).trim();
      console.log(`(æ¨ç†æ¨¡å¼) åˆæ­¥å›¾åƒ prompt: "${actualPrompt}"`);
    } else {
      console.warn(`(æ¨ç†æ¨¡å¼) æ¨¡å‹ (${chosenModelName}) è¾“å‡ºæœªæ‰¾åˆ° <think> ç»“æ„ã€‚å°†ç”¨æ•´ä¸ªè¾“å‡ºã€‚å†…å®¹: "${rawModelOutput}"`);
      actualPrompt = rawModelOutput.trim();
    }
  } else {
    actualPrompt = rawModelOutput.trim();
    console.log(`(éæ¨ç†æ¨¡å¼) è·å–åˆ°çš„ prompt: "${actualPrompt}"`);
  }

  // Final prompt processing and validation
  const promptWords = actualPrompt.split(/\s+/).filter(Boolean);
  const maxWords = 50;
  if (promptWords.length === 0) { console.warn(`å¤„ç†å prompt ä¸ºç©ºï¼Œå›é€€åˆ°åŸå§‹è¾“å…¥: "${sentence}"`); return sentence; }
  if (promptWords.length > maxWords) { actualPrompt = promptWords.slice(0, maxWords).join(" "); console.log(`æˆªæ–­åçš„å›¾åƒ prompt: "${actualPrompt}"`);}
  if (!actualPrompt.includes(",")) { console.warn(`æœ€ç»ˆå¤„ç†åçš„å›¾åƒ prompt ("${actualPrompt}") å¯èƒ½ä¸ç¬¦åˆé¢„æœŸæ ¼å¼ (ç¼ºå°‘é€—å·)ã€‚`); }
  if (actualPrompt.trim().length === 0) { console.error(`å…³é”®é”™è¯¯ï¼šæœ€ç»ˆå›¾åƒ prompt ä¸ºç©ºï¼Œå°†å›é€€åˆ°åŸå§‹ç”¨æˆ·è¾“å…¥: "${sentence}"`); return sentence; }

  console.log(`æœ€ç»ˆç”¨äºå›¾åƒç”Ÿæˆçš„ prompt: "${actualPrompt}"`);
  return actualPrompt;
}

// Generates an image using an external API, supports multiple API keys for rotation
async function generateImage(prompt, imageSize, modelToUse, apiBaseUrl, apiKeysString) {
  console.log(`ä½¿ç”¨æç¤ºè¯ç”Ÿæˆå›¾åƒ (ç›®æ ‡: URL): "${prompt}", å°ºå¯¸: ${imageSize}, æ¨¡å‹: ${modelToUse}, API Base: ${apiBaseUrl}`);

  if (!apiBaseUrl || apiBaseUrl.trim() === "") {
    throw new Error(`å›¾åƒç”Ÿæˆé…ç½®é”™è¯¯: ä¼ å…¥çš„ apiBaseUrl (ç”¨äºæ¨¡å‹ ${modelToUse}) æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚`);
  }
  if (!modelToUse || modelToUse.trim() === "") {
    // This should ideally be caught before calling this function
    console.error("generateImage (URL): å†…éƒ¨é”™è¯¯ - modelToUse å‚æ•°ä¸ºç©ºæˆ–æ— æ•ˆã€‚");
    throw new Error("å›¾åƒç”Ÿæˆé…ç½®é”™è¯¯: å°è¯•ä½¿ç”¨ä¸€ä¸ªæ— æ•ˆçš„æ¨¡å‹åç§° (URL ç”Ÿæˆè·¯å¾„)ã€‚");
  }
  if (!apiKeysString || apiKeysString.trim() === "") {
    throw new Error(`å›¾åƒç”Ÿæˆé…ç½®é”™è¯¯: ä¼ å…¥çš„ apiKeysString (ç”¨äºæ¨¡å‹ ${modelToUse} at ${apiBaseUrl}) æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚`);
  }

  const apiKeys = apiKeysString.split(',')
    .map(key => key.trim())
    .filter(key => key !== "");

  if (apiKeys.length === 0) {
    throw new Error(`å›¾åƒç”Ÿæˆé…ç½®é”™è¯¯: apiKeysString (ç”¨äºæ¨¡å‹ ${modelToUse} at ${apiBaseUrl}) é…ç½®äº†æ— æ•ˆçš„å¯†é’¥ã€‚`);
  }

  let lastError = null;

  for (let i = 0; i < apiKeys.length; i++) {
    const apiKey = apiKeys[i];
    console.log(`å°è¯•ä½¿ç”¨ API å¯†é’¥ (ç´¢å¼•: ${i}, Key: ...${apiKey.slice(-4)}) è°ƒç”¨å›¾åƒç”Ÿæˆ API (${apiBaseUrl.trim()}) (æ¨¡å‹: ${modelToUse.trim()}) ä»¥è·å– URL`);
    const requestBody = {
      prompt: prompt,
      image_size: imageSize,
      num_inference_steps: 50,
      model: modelToUse.trim()
    };

    try {
      const response = await fetch(apiBaseUrl.trim(), {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody),
      });

      if (response.ok) {
        const data = await response.json();
        // Assuming the Flux-type API returns a URL in this structure
        if (data.images && data.images.length > 0 && data.images[0].url) {
          console.log(`ä½¿ç”¨æ¨¡å‹ ${modelToUse.trim()} å’Œå¯†é’¥ (ç´¢å¼•: ${i}) åœ¨ ${apiBaseUrl.trim()} æˆåŠŸç”Ÿæˆçš„å›¾åƒ URL: ${data.images[0].url}`);
          return data.images[0].url;
        } else {
          lastError = `APIå“åº”æ ¼å¼å¼‚å¸¸(URLç”Ÿæˆï¼Œæ¨¡å‹: ${modelToUse.trim()} at ${apiBaseUrl}): æœªæ‰¾åˆ°å›¾åƒURLã€‚å“åº”å†…å®¹: ${JSON.stringify(data, null, 2)}`;
          console.error(lastError + ` (ä½¿ç”¨å¯†é’¥ç´¢å¼•: ${i})`);
        }
      } else {
        const errorText = await response.text();
        lastError = `å›¾åƒ API (URL ç”Ÿæˆ) å“åº”çŠ¶æ€ç : ${response.status} ${response.statusText || ''} (æ¨¡å‹: ${modelToUse.trim()} at ${apiBaseUrl}). è¯¦ç»†é”™è¯¯: ${errorText}`;
        console.error(lastError + ` (ä½¿ç”¨å¯†é’¥ç´¢å¼•: ${i})`);
      }
    } catch (fetchError) {
      lastError = `è°ƒç”¨å›¾åƒ API (URL ç”Ÿæˆ) æ—¶å‘ç”Ÿç½‘ç»œæˆ–å…¶ä»–é”™è¯¯: ${fetchError.message}`;
      console.error(lastError + ` (ä½¿ç”¨å¯†é’¥ç´¢å¼•: ${i})`);
    }
  }

  console.error(`æ‰€æœ‰ API å¯†é’¥ (æ¥è‡ª apiKeysString for ${apiBaseUrl}) å‡å°è¯•å¤±è´¥ (æ¨¡å‹: ${modelToUse.trim()})ã€‚`);
  const finalErrorMessage = `æ‰€æœ‰å›¾åƒç”Ÿæˆ API å¯†é’¥å‡å°è¯•å¤±è´¥ (é’ˆå¯¹æ¨¡å‹ '${modelToUse.trim()}' at ${apiBaseUrl} for URL). æœ€åä¸€æ¬¡é”™è¯¯: ${lastError || 'æœªçŸ¥é”™è¯¯'}ã€‚è¯·æ£€æŸ¥ç›¸å…³ API Key å’Œ API Base çš„é…ç½®ä»¥åŠä¸Šæ¸¸å›¾åƒç”ŸæˆæœåŠ¡çŠ¶æ€ã€‚`;
  throw new Error(finalErrorMessage);
}

// Converts aspect ratio string to image size string
function getImageSize(ratio) {
  const sizeMap = {'1:1':'1024x1024', '1:2':'512x1024', '3:2':'768x512', '3:4':'768x1024', '16:9':'1024x576', '9:16':'576x1024'};
  return sizeMap[ratio] || '1024x1024'; // Default if ratio not found
}

// Proxies image requests to avoid CORS issues or hide original URL
async function handleImageProxy(request) {
  const url = new URL(request.url);
  const originalImageUrl = url.searchParams.get('url');
  if (!originalImageUrl) return new Response("Missing image URL parameter", { status: 400 });

  try {
    console.log(`ä»£ç†è¯·æ±‚å›¾ç‰‡: ${originalImageUrl}`);
    const imageResponse = await fetch(originalImageUrl);
    if (!imageResponse.ok) {
      const errorText = await imageResponse.text();
      console.error(`ä»£ç†å›¾ç‰‡å¤±è´¥: ${imageResponse.status} ${imageResponse.statusText}. è¯¦æƒ…: ${errorText}`);
      return new Response(`Failed to fetch original image: ${imageResponse.status} ${imageResponse.statusText}`, { status: imageResponse.status });
    }
    const contentType = imageResponse.headers.get('Content-Type') || 'image/jpeg';
    const imageArrayBuffer = await imageResponse.arrayBuffer();
    const headers = new Headers({ 'Content-Type': contentType, 'Content-Disposition': 'inline' });
    return new Response(imageArrayBuffer, { status: 200, headers: headers });
  } catch (error) {
    console.error('ä»£ç†å›¾ç‰‡æ—¶å‡ºé”™:', error.message, error.stack);
    return new Response(`Error proxying image: ${error.message}`, { status: 500 });
  }
}

// Main request handler for the Worker
async function handleRequest(request) {
  console.log(`å¤„ç†è¯·æ±‚: ${request.method} ${request.url}`);
  const config = workerConfig || initializeConfig(); // Ensure config is initialized
  // console.log("å½“å‰ Worker é…ç½®:", JSON.stringify(config, null, 2)); // Optional: Log current config for debugging

  const url = new URL(request.url);
  const path = url.pathname;

  try {
    // Ensure config is available for all handlers if they somehow bypass the top-level init
    // (though initializeConfig() should make it globally available via workerConfig)
    if (!workerConfig && path !== '/') { // Allow root path to work even if config fails for some reason, to show welcome.
        console.error("ä¸¥é‡é”™è¯¯: Worker é…ç½®åœ¨ handleRequest ä¸­æœªåˆå§‹åŒ–ã€‚");
        // Attempt re-initialization, though this indicates a deeper issue.
        initializeConfig();
        if (!workerConfig) {
             return new Response(JSON.stringify({ error: { message: "æœåŠ¡å™¨é…ç½®ä¸¥é‡é”™è¯¯ï¼Œæ— æ³•å¤„ç†è¯·æ±‚ã€‚", type: "server_error", code: "config_init_failed_critical" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
        }
    }

    if (path === '/') {
      const readmeUrl = "https://github.com/snakeying/Flux-Cloudflare-API";
      const welcomeMessageHtml = `
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>å›¾åƒç”ŸæˆæœåŠ¡</title>
            <style>
                body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; background-color: #f4f6f8; text-align: center; color: #333; padding: 20px; box-sizing: border-box; }
                .container { padding: 30px; background-color: white; border-radius: 10px; box-shadow: 0 6px 12px rgba(0,0,0,0.1); max-width: 600px; width: 100%; }
                h1 { color: #007bff; margin-bottom: 20px; }
                p { font-size: 1.1em; line-height: 1.6; margin-bottom: 15px; }
                .important-note { background-color: #fff3cd; border-left: 5px solid #ffeeba; padding: 15px; margin-top: 20px; margin-bottom: 20px; text-align: left; border-radius: 5px;}
                .important-note strong { color: #856404; }
                a { color: #0056b3; text-decoration: none; }
                a:hover { text-decoration: underline; }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>âœ¨ å›¾åƒç”ŸæˆæœåŠ¡å·²æˆåŠŸéƒ¨ç½²ï¼ âœ¨</h1>
                <p>ä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹åˆ›ä½œå§ï¼</p>
                <div class="important-note">
                    <p><strong>é‡è¦æç¤ºï¼š</strong>åœ¨å¼€å§‹ä½¿ç”¨å‰ï¼Œè¯·åŠ¡å¿…æ£€æŸ¥æ‰€æœ‰ç¯å¢ƒå˜é‡é…ç½®æ˜¯å¦ç¬¦åˆæ‚¨çš„éœ€æ±‚ã€‚</p>
                    <p>å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥é˜… <a href="${readmeUrl}" target="_blank" rel="noopener noreferrer">é¡¹ç›® README æ–‡æ¡£</a> è·å–è¯¦ç»†æŒ‡å¼•ã€‚</p>
                </div>
                <p>è®°å¾—åŠæ—¶ä¿å­˜æ‚¨ç”Ÿæˆçš„æ»¡æ„ä½œå“å“¦ã€‚ğŸ˜Š</p>
            </div>
        </body>
        </html>
      `;
      return new Response(welcomeMessageHtml, {
        headers: { 'Content-Type': 'text/html; charset=utf-8' }
      });
    }
    else if (path === '/v1/chat/completions') {
      return await handleChatCompletions(request);
    } else if (path === '/v1/models') {
      return await handleModels(request);
    } else if (path === '/image-proxy') {
      return await handleImageProxy(request);
    } else if (path === '/health' || path === '/v1/health') {
      return new Response(JSON.stringify({ status: 'ok' }), { headers: { 'Content-Type': 'application/json' } });
    } else {
      return new Response(JSON.stringify({ error: { message: `è·¯å¾„ ${path} æœªæ‰¾åˆ°`, type: "invalid_request_error", code: "path_not_found" } }), { status: 404, headers: { 'Content-Type': 'application/json' } });
    }
  } catch (e) {
    console.error("ä¸»å¤„ç†ç¨‹åºé”™è¯¯:", e.message, e.stack);
    if (e.message.includes("é…ç½®é”™è¯¯:") || e.message.includes("configuration error:") || e.message.includes("æ‰€æœ‰å›¾åƒç”Ÿæˆ API å¯†é’¥å‡å°è¯•å¤±è´¥")) {
      return new Response(JSON.stringify({ error: { message: e.message, type: "configuration_error", code: "env_config_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
    }
    return new Response(JSON.stringify({ error: { message: `æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: ${e.message}`, type: "server_error", code: "unhandled_exception" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }
}

addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request).catch(err => {
    console.error("Fetchäº‹ä»¶æœ€ç»ˆé”™è¯¯:", err.message, err.stack);
    if (err.message.includes("é…ç½®é”™è¯¯:") || err.message.includes("configuration error:") || err.message.includes("æ‰€æœ‰å›¾åƒç”Ÿæˆ API å¯†é’¥å‡å°è¯•å¤±è´¥")) {
      return new Response(JSON.stringify({ error: { message: err.message, type: "configuration_error", code: "env_config_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
    }
    return new Response(JSON.stringify({ error: { message: "æœåŠ¡å™¨æ„å¤–é”™è¯¯ã€‚", type: "catastrophic_error", code:"fatal_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }));
});
