// Cloudflare Worker for Image Generation API with Image Proxy
// and ensuring Markdown content is just the image link

// Helper function to access environment variables
const env = name => globalThis[name];

// --- System Prompts ---
// For OPENAI_MODEL (non-reasoning)
const systemPromptForNonReasoning = `TEXT-TO-IMAGE PROMPT GENERATOR
## OBJECTIVE
Convert user input into a concise, effective text-to-image prompt.
## OUTPUT STRUCTURE
- Single paragraph, comma-separated
- Maximum 50 words, aim for 30-40
- Always start with: "masterpiece, best quality, 8k"
- Include: style, main subject, key scene elements
- Generate ONE prompt in English
- Return ONLY the generated prompt.
## EXAMPLES
User Input: "A cat sitting on a windowsill"
Output: masterpiece, best quality, 8k, photorealistic, orange tabby cat, alert posture, sunlit wooden windowsill, soft focus cityscape outside, warm afternoon light`;

// For OPENAI_MODEL_REASONING
const systemPromptForReasoning = `TEXT-TO-IMAGE PROMPT GENERATOR
## OBJECTIVE
Convert user input into a concise, effective text-to-image prompt for image generation.

## YOUR PROCESS & FULL RESPONSE STRUCTURE
1.  **Think Step (Internal Monologue):** First, think about the request. This thinking process MUST be enclosed in <think></think> tags.
2.  **Image Prompt Output:** Immediately AFTER the closing </think> tag, you MUST provide the generated image prompt.

## IMAGE PROMPT SPECIFICATIONS (This applies to the part of your response AFTER </think>)
*   It MUST be a single paragraph, comma-separated.
*   It MUST be maximum 50 words, ideally 30-40 words.
*   It MUST always start with: "masterpiece, best quality, 8k".
*   Include: style, main subject, key scene elements.
*   Generate ONE prompt in English.

## EXAMPLE OF YOUR FULL RESPONSE TO ME:
<think>The user's input is "ä¸€åªæœªæ¥åŸå¸‚çš„çŒ«". I need to translate this and come up with a prompt. "A cat in a futuristic city." Style could be cyberpunk or sleek sci-fi. Let's go with cyberpunk for more visual interest. Key elements: cat, futuristic city, neon lights, rain. The cat could be a sleek black cat. The city should have towering, glowing skyscrapers. The prompt needs to start with the standard keywords and be within word limits.</think>masterpiece, best quality, 8k, cyberpunk, sleek black cat, perched on a neon-lit ledge, overlooking a sprawling futuristic metropolis, rain-slicked streets, towering glowing skyscrapers, vibrant and moody atmosphere

## CRITICAL: THE ACTUAL IMAGE PROMPT PART OF YOUR RESPONSE
Based on the example above, the part of your response that I will extract and use AS THE IMAGE PROMPT would be:
"masterpiece, best quality, 8k, cyberpunk, sleek black cat, perched on a neon-lit ledge, overlooking a sprawling futuristic metropolis, rain-slicked streets, towering glowing skyscrapers, vibrant and moody atmosphere"
Ensure your output after </think> precisely matches this clean format, with no extra text, newlines, or explanations.

## USER INPUT FOR YOU TO PROCESS:
Input: {sentence}
Output: (Your full response, starting with <think> if you perform that step, followed by the image prompt as specified)
`;


// éªŒè¯ API å¯†é’¥ (Workerçš„å…¨å±€è®¤è¯)
function validateWorkerApiKey(request) {
  const authHeader = request.headers.get('Authorization');
  if (!authHeader || !authHeader.startsWith('Bearer ')) {
    return false;
  }
  const providedKey = authHeader.substring(7);
  const validKey = env('AUTHORIZED_API_KEY');
  if (!validKey || validKey.trim() === "") {
      console.error("Workerå…¨å±€è®¤è¯é…ç½®é”™è¯¯: AUTHORIZED_API_KEY æœªè®¾ç½®ã€‚");
      return false;
  }
  return providedKey === validKey;
}

// å¤„ç†æ¨¡å‹åˆ—è¡¨è¯·æ±‚
async function handleModels(request) {
  if (!validateWorkerApiKey(request)) {
    return new Response(JSON.stringify({ error: { message: "è®¤è¯å¤±è´¥ï¼Œæ— æ•ˆçš„ API å¯†é’¥", type: "invalid_request_error", code: "invalid_api_key" } }), { status: 401, headers: { 'Content-Type': 'application/json' } });
  }

  // --- MODIFIED: Dynamically generate model list based on IMAGE_GEN_MODEL ---
  const imageGenModelEnv = env('IMAGE_GEN_MODEL');
  let modelsData = [];

  if (imageGenModelEnv && imageGenModelEnv.trim() !== "") {
    const modelNames = imageGenModelEnv.split(',').map(name => name.trim()).filter(name => name);
    if (modelNames.length > 0) {
      modelsData = modelNames.map(modelId => ({
        id: modelId,
        object: "model",
        created: Math.floor(Date.now() / 1000) - 8000, // Consistent timestamp logic
        owned_by: "organization-owner", // Can be made configurable if needed
        permission: [{
          id: `modelperm-${modelId.replace(/[^a-zA-Z0-9-_]/g, '_')}`, // Ensure valid ID
          object: "model_permission",
          created: Math.floor(Date.now() / 1000) - 8000,
          allow_create_engine: false,
          allow_sampling: true,
          allow_logprobs: false,
          allow_search_indices: false,
          allow_view: true,
          allow_fine_tuning: false,
          organization: "*",
          group: null,
          is_blocking: false
        }],
        root: modelId,
        parent: null
      }));
      console.log(`æ¨¡å‹åˆ—è¡¨æ¥å£: æˆåŠŸåŠ è½½ ${modelNames.length} ä¸ªæ¨¡å‹: ${modelNames.join(', ')}`);
    } else {
      console.warn("æ¨¡å‹åˆ—è¡¨æ¥å£: IMAGE_GEN_MODEL ç¯å¢ƒå˜é‡å·²è®¾ç½®ä½†è§£æåä¸ºç©ºåˆ—è¡¨ã€‚");
      // Fallback to a default or empty list if IMAGE_GEN_MODEL is set but results in no models
      modelsData = [{ id: "flux-image-gen-default-config-issue", object: "model", /* ... minimal valid structure ... */ }];
    }
  } else {
    console.warn("æ¨¡å‹åˆ—è¡¨æ¥å£: IMAGE_GEN_MODEL ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚è¿”å›é»˜è®¤æ¨¡å‹ 'flux-image-gen-default'ã€‚");
    // Fallback if IMAGE_GEN_MODEL is not set - original behavior or a defined default
    modelsData = [{ id: "flux-image-gen-default", object: "model", created: Math.floor(Date.now() / 1000) - 8000, owned_by: "organization-owner", permission: [{ id: "modelperm-flux-img-default", object: "model_permission", created: Math.floor(Date.now() / 1000) - 8000, allow_create_engine: false, allow_sampling: true, allow_logprobs: false, allow_search_indices: false, allow_view: true, allow_fine_tuning: false, organization: "*", group: null, is_blocking: false }], root: "flux-image-gen-default", parent: null }];
  }
  // --- END MODIFICATION ---

  return new Response(JSON.stringify({ object: "list", data: modelsData }), { headers: { 'Content-Type': 'application/json' } });
}

// å¤„ç† chat completions è¯·æ±‚
async function handleChatCompletions(request) {
  if (request.method !== 'POST') return new Response(JSON.stringify({ error: { message: "æ–¹æ³•ä¸å…è®¸ï¼Œè¯·ä½¿ç”¨ POST è¯·æ±‚", type: "invalid_request_error", code:"method_not_allowed" } }), { status: 405, headers: { 'Content-Type': 'application/json' } });
  if (!validateWorkerApiKey(request)) return new Response(JSON.stringify({ error: { message: "è®¤è¯å¤±è´¥ï¼Œæ— æ•ˆçš„ API å¯†é’¥", type: "invalid_request_error", code:"invalid_api_key" } }), { status: 401, headers: { 'Content-Type': 'application/json' } });

  let requestData;
  try { requestData = await request.json(); } catch (e) { return new Response(JSON.stringify({ error: { message: "æ— æ³•è§£æè¯·æ±‚ä½“ï¼Œè¯·æä¾›æœ‰æ•ˆçš„ JSON", type: "invalid_request_error", code:"invalid_json" } }), { status: 400, headers: { 'Content-Type': 'application/json' } }); }
  if (!requestData.messages || !Array.isArray(requestData.messages) || requestData.messages.length === 0) return new Response(JSON.stringify({ error: { message: "è¯·æ±‚ç¼ºå°‘å¿…éœ€çš„ messages å­—æ®µæˆ–æ ¼å¼ä¸æ­£ç¡®", type: "invalid_request_error", code:"invalid_parameters" } }), { status: 400, headers: { 'Content-Type': 'application/json' } });

  // --- ADDED: Validate requestData.model (Strict Mode) ---
  const requestedModelUntrimmed = requestData.model; // Keep original for logging if needed, but use trimmed for logic

  if (!requestedModelUntrimmed || typeof requestedModelUntrimmed !== 'string' || requestedModelUntrimmed.trim() === "") {
    console.warn(`Chat Completions: è¯·æ±‚ä½“ç¼ºå°‘ 'model' å­—æ®µæˆ–ä¸ºç©ºã€‚è¯·æ±‚ä½“: ${JSON.stringify(requestData)}`);
    return new Response(JSON.stringify({
      error: {
        message: "è¯·æ±‚ä½“ä¸­å¿…é¡»åŒ…å«æœ‰æ•ˆçš„ 'model' å­—æ®µï¼Œç”¨äºæŒ‡å®šå›¾åƒç”Ÿæˆæ¨¡å‹ã€‚",
        type: "invalid_request_error",
        code: "missing_model_field"
      }
    }), { status: 400, headers: { 'Content-Type': 'application/json' } });
  }
  const requestedModel = requestedModelUntrimmed.trim(); // Use trimmed version from now on

  const allowedModelsString = env('IMAGE_GEN_MODEL');
  if (!allowedModelsString || allowedModelsString.trim() === "") {
    console.error("Chat Completions é…ç½®é”™è¯¯: IMAGE_GEN_MODEL ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚æ— æ³•éªŒè¯ç”¨æˆ·è¯·æ±‚çš„æ¨¡å‹ã€‚");
    return new Response(JSON.stringify({
      error: {
        message: "æœåŠ¡å™¨é…ç½®é”™è¯¯ï¼šå¯ç”¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹åˆ—è¡¨æœªé…ç½®ã€‚",
        type: "configuration_error", // More specific than server_error for this case
        code: "image_models_not_configured"
      }
    }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }

  const allowedModels = allowedModelsString.split(',').map(name => name.trim()).filter(name => name);
  if (allowedModels.length === 0) {
      console.error(`Chat Completions é…ç½®é”™è¯¯: IMAGE_GEN_MODEL ç¯å¢ƒå˜é‡ ("${allowedModelsString}") é…ç½®æ— æ•ˆï¼Œè§£æåæ— å¯ç”¨æ¨¡å‹ã€‚`);
      return new Response(JSON.stringify({
        error: {
          message: "æœåŠ¡å™¨é…ç½®é”™è¯¯ï¼šå¯ç”¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹åˆ—è¡¨é…ç½®æ— æ•ˆã€‚",
          type: "configuration_error",
          code: "image_models_invalid_config"
        }
      }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }

  if (!allowedModels.includes(requestedModel)) {
    console.warn(`Chat Completions: ç”¨æˆ·è¯·æ±‚çš„æ¨¡å‹ '${requestedModel}' ä¸åœ¨å…è®¸çš„åˆ—è¡¨ [${allowedModels.join(', ')}] ä¸­ã€‚`);
    return new Response(JSON.stringify({
      error: {
        message: `è¯·æ±‚çš„å›¾åƒç”Ÿæˆæ¨¡å‹ '${requestedModel}' ä¸å—æ”¯æŒã€‚å¯ç”¨çš„æ¨¡å‹æœ‰: ${allowedModels.join(', ')}ã€‚`,
        type: "invalid_request_error",
        code: "unsupported_image_model"
      }
    }), { status: 400, headers: { 'Content-Type': 'application/json' } });
  }
  console.log(`Chat Completions: ç”¨æˆ·è¯·æ±‚ä½¿ç”¨æ¨¡å‹ '${requestedModel}' (å·²é€šè¿‡éªŒè¯)ã€‚`);
  // --- END ADDED VALIDATION ---

  try {
    // Pass the validated requestedModel to handleImageGeneration
    return await handleImageGeneration(requestData, request, requestedModel);
  } catch (error) {
    console.error('å¤„ç† chat completions è¯·æ±‚æ—¶å‡ºé”™:', error.message, error.stack);
    if (error.message.includes("é…ç½®é”™è¯¯:") || error.message.includes("configuration error:") || error.message.includes("æ‰€æœ‰å›¾åƒç”Ÿæˆ API å¯†é’¥å‡å°è¯•å¤±è´¥")) {
        return new Response(JSON.stringify({ error: { message: error.message, type: "configuration_error", code: "env_config_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
    }
    return new Response(JSON.stringify({ error: { message: `å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: ${error.message}`, type: "server_error", code: "internal_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }
}

// å¤„ç†å›¾åƒç”Ÿæˆè¯·æ±‚
// MODIFIED: Added chosenModelName parameter
async function handleImageGeneration(requestData, request, chosenModelName) {
  const lastMessage = requestData.messages[requestData.messages.length - 1];
  let userPrompt = lastMessage.content;
  let imageSize = '1024x1024';
  const sizeMatch = userPrompt.match(/([\d]+:[\d]+)/);
  if (sizeMatch && sizeMatch[1]) {
      userPrompt = userPrompt.replace(sizeMatch[1], '').trim();
      imageSize = getImageSize(sizeMatch[1]);
      console.log(`å›¾åƒå°ºå¯¸ä»ç”¨æˆ·è¾“å…¥ä¸­æå–: ${sizeMatch[1]}, è§£æä¸º: ${imageSize}`);
  }

  const revisedPrompt = await reviseSentenceToPrompt(userPrompt); // Assuming reviseSentenceToPrompt doesn't need the model name
  if (!revisedPrompt || revisedPrompt.trim() === "") throw new Error("Prompt ä¼˜åŒ–åä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå›¾åƒã€‚");

  // MODIFIED: Pass chosenModelName to generateImage
  const originalImageUrl = await generateImage(revisedPrompt, imageSize, chosenModelName);
  if (!originalImageUrl) throw new Error('å›¾åƒç”ŸæˆæœåŠ¡æœªè¿”å›æœ‰æ•ˆçš„å›¾åƒ URL (æ‰€æœ‰Keyå°è¯•åä¾ç„¶å¤±è´¥)');

  const encodedImageUrl = encodeURIComponent(originalImageUrl);
  const proxyImageUrl = `${new URL(request.url).origin}/image-proxy?url=${encodedImageUrl}`;
  const markdownImageString = `![Image](${proxyImageUrl})\n\nä¼˜åŒ–åçš„æç¤ºè¯: ${revisedPrompt}`;

  // MODIFIED: Use chosenModelName in the response
  const responseModelId = chosenModelName; // Or env('IMAGE_GEN_MODEL') if it was a single fixed model before, now it's dynamic

  return new Response(JSON.stringify({
    id: `imggen-${Date.now()}`, object: "chat.completion", created: Math.floor(Date.now() / 1000),
    model: responseModelId, // Use the actual model chosen for generation
    choices: [{ index: 0, message: { role: "assistant", content: markdownImageString }, finish_reason: "stop" }],
    usage: { prompt_tokens: userPrompt.length, completion_tokens: markdownImageString.length, total_tokens: userPrompt.length + markdownImageString.length }
  }), { headers: { 'Content-Type': 'application/json' } });
}

// å‡½æ•°ï¼šä¿®æ”¹å¥å­ä¸ºæç¤ºè¯
async function reviseSentenceToPrompt(sentence) {
  console.log(`åŸå§‹ç”¨æˆ·è¾“å…¥ç”¨äºä¼˜åŒ–: "${sentence}"`);

  const promptApiKey = env('OPENAI_API_KEY');
  if (!promptApiKey || promptApiKey.trim() === "") throw new Error("æç¤ºè¯ä¼˜åŒ–é…ç½®é”™è¯¯: ç¯å¢ƒå˜é‡ OPENAI_API_KEY æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚");

  const modelForNonReasoning = env('OPENAI_MODEL');
  const modelForReasoning = env('OPENAI_MODEL_REASONING');
  let chosenModelName = "", chosenSystemPrompt = "", isReasoningMode = false;
  const nonReasoningSet = modelForNonReasoning && modelForNonReasoning.trim() !== "";
  const reasoningSet = modelForReasoning && modelForReasoning.trim() !== "";

  if (reasoningSet) {
    if (nonReasoningSet) throw new Error("æç¤ºè¯ä¼˜åŒ–é…ç½®é”™è¯¯: OPENAI_MODEL å’Œ OPENAI_MODEL_REASONING ä¸èƒ½åŒæ—¶é…ç½®ã€‚è¯·åªé€‰æ‹©ä¸€ä¸ªã€‚");
    chosenModelName = modelForReasoning.trim(); chosenSystemPrompt = systemPromptForReasoning; isReasoningMode = true;
    console.log(`ä½¿ç”¨æ¨ç†æ¨¡å‹è¿›è¡Œæç¤ºè¯ä¼˜åŒ–: ${chosenModelName}`);
  } else if (nonReasoningSet) {
    chosenModelName = modelForNonReasoning.trim(); chosenSystemPrompt = systemPromptForNonReasoning;
    console.log(`ä½¿ç”¨éæ¨ç†æ¨¡å‹è¿›è¡Œæç¤ºè¯ä¼˜åŒ–: ${chosenModelName}`);
  } else {
    throw new Error("æç¤ºè¯ä¼˜åŒ–é…ç½®é”™è¯¯: OPENAI_MODEL æˆ– OPENAI_MODEL_REASONING å¿…é¡»é…ç½®ä¸€ä¸ªã€‚");
  }

  const promptApiBase = env('OPENAI_API_BASE');
  if (!promptApiBase || promptApiBase.trim() === "") {
      throw new Error("æç¤ºè¯ä¼˜åŒ–é…ç½®é”™è¯¯: OPENAI_API_BASE æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ README æŒ‡å¯¼è®¾ç½®ä¸º API çš„åŸºç¡€ URL (ä¾‹å¦‚: https://api.openai.com/v1)ã€‚");
  }
  const finalPromptApiUrl = `${promptApiBase.trim()}/chat/completions`;

  const openaiUserMessage = `Input: ${sentence}\nOutput:`;
  console.log(`å‘é€è¯·æ±‚åˆ°æç¤ºè¯ä¼˜åŒ– API (${finalPromptApiUrl}) (æ¨¡å‹: ${chosenModelName})`);
  const response = await fetch(finalPromptApiUrl, {
    method: 'POST',
    headers: { 'Authorization': `Bearer ${promptApiKey}`, 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: chosenModelName,
      messages: [{ role: 'system', content: chosenSystemPrompt }, { role: 'user', content: openaiUserMessage }]
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error(`æç¤ºè¯ä¼˜åŒ– API å“åº”çŠ¶æ€ç : ${response.status}. ç«¯ç‚¹: ${finalPromptApiUrl}, æ¨¡å‹: ${chosenModelName}. å“åº”: ${errorText}`);
    console.warn(`æç¤ºè¯ä¼˜åŒ– API è°ƒç”¨å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ç”¨æˆ·è¾“å…¥: "${sentence}"`);
    return sentence;
  }
  let data;
  try { data = await response.json(); } catch (e) { console.warn(`è§£æJSONå¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ç”¨æˆ·è¾“å…¥: "${sentence}"`); return sentence; }
  if (!data.choices || data.choices.length === 0 || !data.choices[0].message || !data.choices[0].message.content) { console.warn(`APIå“åº”ç»“æ„ä¸ç¬¦ï¼Œå°†ä½¿ç”¨åŸå§‹ç”¨æˆ·è¾“å…¥: "${sentence}"`); return sentence; }

  let rawModelOutput = data.choices[0].message.content;
  console.log(`æç¤ºè¯ä¼˜åŒ–æ¨¡å‹ (${chosenModelName}) è¿”å›çš„åŸå§‹è¾“å‡º: "${rawModelOutput}"`);

  let actualPrompt = "";
  let thinkingProcess = "";

  if (isReasoningMode) {
    const thinkStartTag = "<think>"; const thinkEndTag = "</think>";
    const thinkStartIndex = rawModelOutput.indexOf(thinkStartTag);
    const thinkEndIndex = rawModelOutput.indexOf(thinkEndTag, thinkStartIndex);
    if (thinkStartIndex !== -1 && thinkEndIndex !== -1 && thinkEndIndex > thinkStartIndex) {
      thinkingProcess = rawModelOutput.substring(thinkStartIndex + thinkStartTag.length, thinkEndIndex).trim();
      console.log(`(æ¨ç†æ¨¡å¼) æå–åˆ°çš„æ€è€ƒè¿‡ç¨‹: "${thinkingProcess}"`);
      actualPrompt = rawModelOutput.substring(thinkEndIndex + thinkEndTag.length).trim();
      console.log(`(æ¨ç†æ¨¡å¼) åˆæ­¥å›¾åƒ prompt: "${actualPrompt}"`);
    } else {
      console.warn(`(æ¨ç†æ¨¡å¼) æ¨¡å‹ (${chosenModelName}) è¾“å‡ºæœªæ‰¾åˆ° <think> ç»“æ„ã€‚å°†ç”¨æ•´ä¸ªè¾“å‡ºã€‚å†…å®¹: "${rawModelOutput}"`);
      actualPrompt = rawModelOutput.trim();
    }
  } else {
    actualPrompt = rawModelOutput.trim();
    console.log(`(éæ¨ç†æ¨¡å¼) è·å–åˆ°çš„ prompt: "${actualPrompt}"`);
  }

  const promptWords = actualPrompt.split(/\s+/).filter(Boolean);
  const maxWords = 50;
  if (promptWords.length === 0) { console.warn(`å¤„ç†å prompt ä¸ºç©ºï¼Œå›é€€åˆ°åŸå§‹è¾“å…¥: "${sentence}"`); return sentence; }
  if (promptWords.length > maxWords) { actualPrompt = promptWords.slice(0, maxWords).join(" "); console.log(`æˆªæ–­åçš„å›¾åƒ prompt: "${actualPrompt}"`);}
  if (!actualPrompt.includes(",")) { console.warn(`æœ€ç»ˆå¤„ç†åçš„å›¾åƒ prompt ("${actualPrompt}") å¯èƒ½ä¸ç¬¦åˆé¢„æœŸæ ¼å¼ (ç¼ºå°‘é€—å·)ã€‚`); }
  if (actualPrompt.trim().length === 0) { console.error(`å…³é”®é”™è¯¯ï¼šæœ€ç»ˆå›¾åƒ prompt ä¸ºç©ºï¼Œå°†å›é€€åˆ°åŸå§‹ç”¨æˆ·è¾“å…¥: "${sentence}"`); return sentence; }

  console.log(`æœ€ç»ˆç”¨äºå›¾åƒç”Ÿæˆçš„ prompt: "${actualPrompt}"`);
  return actualPrompt;
}

// å‡½æ•°ï¼šç”Ÿæˆå›¾åƒ (æ”¯æŒå¤šKEYè½®å€¼)
// MODIFIED: Added modelToUse parameter
async function generateImage(prompt, imageSize, modelToUse) {
  // Log now includes the specific model being used for this generation attempt
  console.log(`ä½¿ç”¨æç¤ºè¯ç”Ÿæˆå›¾åƒ: "${prompt}", å°ºå¯¸: ${imageSize}, æ¨¡å‹: ${modelToUse}`);

  const imageApiBaseUrl = env('IMAGE_GEN_API_BASE');
  // const imageModelName = env('IMAGE_GEN_MODEL'); // This is now passed as modelToUse
  const imageApiKeysString = env('IMAGE_GEN_API_KEY');

  if (!imageApiBaseUrl || imageApiBaseUrl.trim() === "") {
    throw new Error("å›¾åƒç”Ÿæˆé…ç½®é”™è¯¯: ç¯å¢ƒå˜é‡ IMAGE_GEN_API_BASE æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚");
  }
  // The modelToUse itself is validated before this function is called.
  // We can add a check here for robustness, though it should theoretically always be valid.
  if (!modelToUse || modelToUse.trim() === "") {
    console.error("generateImage: å†…éƒ¨é”™è¯¯ - modelToUse å‚æ•°ä¸ºç©ºæˆ–æ— æ•ˆã€‚");
    throw new Error("å›¾åƒç”Ÿæˆé…ç½®é”™è¯¯: å°è¯•ä½¿ç”¨ä¸€ä¸ªæ— æ•ˆçš„æ¨¡å‹åç§°ã€‚");
  }
  if (!imageApiKeysString || imageApiKeysString.trim() === "") {
    throw new Error("å›¾åƒç”Ÿæˆé…ç½®é”™è¯¯: ç¯å¢ƒå˜é‡ IMAGE_GEN_API_KEY æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚");
  }

  const apiKeys = imageApiKeysString.split(',')
    .map(key => key.trim())
    .filter(key => key !== "");

  if (apiKeys.length === 0) {
    throw new Error("å›¾åƒç”Ÿæˆé…ç½®é”™è¯¯: IMAGE_GEN_API_KEY é…ç½®äº†æ— æ•ˆçš„å¯†é’¥ã€‚è¯·ç¡®ä¿æ ¼å¼ä¸º 'key1,key2,key3' ä¸”å¯†é’¥éç©ºã€‚");
  }

  let lastError = null;

  for (let i = 0; i < apiKeys.length; i++) {
    const apiKey = apiKeys[i];
    // Log now correctly shows the modelToUse for each attempt
    console.log(`å°è¯•ä½¿ç”¨ API å¯†é’¥ (ç´¢å¼•: ${i}, Key: ...${apiKey.slice(-4)}) è°ƒç”¨å›¾åƒç”Ÿæˆ API (${imageApiBaseUrl.trim()}) (æ¨¡å‹: ${modelToUse.trim()})`);
    const requestBody = {
      prompt: prompt,
      image_size: imageSize,
      num_inference_steps: 50, // This could also be made configurable
      model: modelToUse.trim() // MODIFIED: Use the passed modelToUse
    };

    try {
      const response = await fetch(imageApiBaseUrl.trim(), {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody),
      });

      if (response.ok) {
        const data = await response.json();
        if (data.images && data.images.length > 0 && data.images[0].url) {
          console.log(`ä½¿ç”¨æ¨¡å‹ ${modelToUse.trim()} å’Œå¯†é’¥ (ç´¢å¼•: ${i}) åœ¨ ${imageApiBaseUrl.trim()} æˆåŠŸç”Ÿæˆçš„å›¾åƒ URL: ${data.images[0].url}`);
          return data.images[0].url;
        } else {
          lastError = `APIå“åº”æ ¼å¼å¼‚å¸¸(å›¾åƒç”Ÿæˆï¼Œæ¨¡å‹: ${modelToUse.trim()}): æœªæ‰¾åˆ°å›¾åƒURLã€‚å“åº”å†…å®¹: ${JSON.stringify(data, null, 2)}`;
          console.error(lastError + ` (ä½¿ç”¨å¯†é’¥ç´¢å¼•: ${i})`);
        }
      } else {
        const errorText = await response.text();
        lastError = `å›¾åƒ API å“åº”çŠ¶æ€ç : ${response.status} ${response.statusText || ''} (æ¨¡å‹: ${modelToUse.trim()}). è¯¦ç»†é”™è¯¯: ${errorText}`;
        console.error(lastError + ` (ä½¿ç”¨å¯†é’¥ç´¢å¼•: ${i})`);
      }
    } catch (fetchError) {
      lastError = `è°ƒç”¨å›¾åƒ API æ—¶å‘ç”Ÿç½‘ç»œæˆ–å…¶ä»–é”™è¯¯: ${fetchError.message}`;
      console.error(lastError + ` (ä½¿ç”¨å¯†é’¥ç´¢å¼•: ${i})`);
    }
  }

  console.error(`æ‰€æœ‰ IMAGE_GEN_API_KEY å‡å°è¯•å¤±è´¥ (æ¨¡å‹: ${modelToUse.trim()})ã€‚`);
  const finalErrorMessage = `æ‰€æœ‰å›¾åƒç”Ÿæˆ API å¯†é’¥å‡å°è¯•å¤±è´¥ (é’ˆå¯¹æ¨¡å‹ '${modelToUse.trim()}'). æœ€åä¸€æ¬¡é”™è¯¯: ${lastError || 'æœªçŸ¥é”™è¯¯'}ã€‚è¯·æ£€æŸ¥ IMAGE_GEN_API_KEY çš„é…ç½®ä»¥åŠä¸Šæ¸¸å›¾åƒç”ŸæˆæœåŠ¡çŠ¶æ€ã€‚`;
  throw new Error(finalErrorMessage);
}


// å‡½æ•°ï¼šæ ¹æ®æ¯”ä¾‹è·å–å›¾åƒå¤§å°
function getImageSize(ratio) {
  const sizeMap = {'1:1':'1024x1024', '1:2':'512x1024', '3:2':'768x512', '3:4':'768x1024', '16:9':'1024x576', '9:16':'576x1024'};
  return sizeMap[ratio] || '1024x1024';
}

// å¤„ç†å›¾ç‰‡ä»£ç†è¯·æ±‚çš„å‡½æ•°
async function handleImageProxy(request) {
  const url = new URL(request.url);
  const originalImageUrl = url.searchParams.get('url');
  if (!originalImageUrl) return new Response("Missing image URL parameter", { status: 400 });

  try {
    console.log(`ä»£ç†è¯·æ±‚å›¾ç‰‡: ${originalImageUrl}`);
    const imageResponse = await fetch(originalImageUrl);
    if (!imageResponse.ok) {
      const errorText = await imageResponse.text();
      console.error(`ä»£ç†å›¾ç‰‡å¤±è´¥: ${imageResponse.status} ${imageResponse.statusText}. è¯¦æƒ…: ${errorText}`);
      return new Response(`Failed to fetch original image: ${imageResponse.status} ${imageResponse.statusText}`, { status: imageResponse.status });
    }
    const contentType = imageResponse.headers.get('Content-Type') || 'image/jpeg';
    const imageArrayBuffer = await imageResponse.arrayBuffer();
    const headers = new Headers({ 'Content-Type': contentType, 'Content-Disposition': 'inline' });
    return new Response(imageArrayBuffer, { status: 200, headers: headers });
  } catch (error) {
    console.error('ä»£ç†å›¾ç‰‡æ—¶å‡ºé”™:', error.message, error.stack);
    return new Response(`Error proxying image: ${error.message}`, { status: 500 });
  }
}

// ä¸»å¤„ç†ç¨‹åº
async function handleRequest(request) {
  console.log(`å¤„ç†è¯·æ±‚: ${request.method} ${request.url}`);
  const url = new URL(request.url);
  const path = url.pathname;

  try {
    if (path === '/') {
      const readmeUrl = "https://github.com/snakeying/Flux-Cloudflare-API";
      const welcomeMessageHtml = `
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale-1.0">
            <title>å›¾åƒç”ŸæˆæœåŠ¡</title>
            <style>
                body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; background-color: #f4f6f8; text-align: center; color: #333; padding: 20px; box-sizing: border-box; }
                .container { padding: 30px; background-color: white; border-radius: 10px; box-shadow: 0 6px 12px rgba(0,0,0,0.1); max-width: 600px; width: 100%; }
                h1 { color: #007bff; margin-bottom: 20px; }
                p { font-size: 1.1em; line-height: 1.6; margin-bottom: 15px; }
                .important-note { background-color: #fff3cd; border-left: 5px solid #ffeeba; padding: 15px; margin-top: 20px; margin-bottom: 20px; text-align: left; border-radius: 5px;}
                .important-note strong { color: #856404; }
                a { color: #0056b3; text-decoration: none; }
                a:hover { text-decoration: underline; }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>âœ¨ å›¾åƒç”ŸæˆæœåŠ¡å·²æˆåŠŸéƒ¨ç½²ï¼ âœ¨</h1>
                <p>ä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹åˆ›ä½œå§ï¼</p>
                <div class="important-note">
                    <p><strong>é‡è¦æç¤ºï¼š</strong>åœ¨å¼€å§‹ä½¿ç”¨å‰ï¼Œè¯·åŠ¡å¿…æ£€æŸ¥æ‰€æœ‰ç¯å¢ƒå˜é‡é…ç½®æ˜¯å¦ç¬¦åˆæ‚¨çš„éœ€æ±‚ã€‚</p>
                    <p>å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥é˜… <a href="${readmeUrl}" target="_blank" rel="noopener noreferrer">é¡¹ç›® README æ–‡æ¡£</a> è·å–è¯¦ç»†æŒ‡å¼•ã€‚</p>
                </div>
                <p>è®°å¾—åŠæ—¶ä¿å­˜æ‚¨ç”Ÿæˆçš„æ»¡æ„ä½œå“å“¦ã€‚ğŸ˜Š</p>
            </div>
        </body>
        </html>
      `;
      return new Response(welcomeMessageHtml, {
        headers: { 'Content-Type': 'text/html; charset=utf-8' }
      });
    }
    else if (path === '/v1/chat/completions') {
      return await handleChatCompletions(request);
    } else if (path === '/v1/models') {
      return await handleModels(request);
    } else if (path === '/image-proxy') {
      return await handleImageProxy(request);
    } else if (path === '/health' || path === '/v1/health') {
      return new Response(JSON.stringify({ status: 'ok' }), { headers: { 'Content-Type': 'application/json' } });
    } else {
      return new Response(JSON.stringify({ error: { message: `è·¯å¾„ ${path} æœªæ‰¾åˆ°`, type: "invalid_request_error", code: "path_not_found" } }), { status: 404, headers: { 'Content-Type': 'application/json' } });
    }
  } catch (e) {
    console.error("ä¸»å¤„ç†ç¨‹åºé”™è¯¯:", e.message, e.stack);
    // Ensure specific configuration errors are bubbled up with the right type
    if (e.message.includes("é…ç½®é”™è¯¯:") || e.message.includes("configuration error:") || e.message.includes("æ‰€æœ‰å›¾åƒç”Ÿæˆ API å¯†é’¥å‡å°è¯•å¤±è´¥")) {
      return new Response(JSON.stringify({ error: { message: e.message, type: "configuration_error", code: "env_config_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
    }
    return new Response(JSON.stringify({ error: { message: `æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: ${e.message}`, type: "server_error", code: "unhandled_exception" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }
}

addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request).catch(err => {
    console.error("Fetchäº‹ä»¶æœ€ç»ˆé”™è¯¯:", err.message, err.stack);
    // Consistent error typing for configuration issues at the top level
    if (err.message.includes("é…ç½®é”™è¯¯:") || err.message.includes("configuration error:") || err.message.includes("æ‰€æœ‰å›¾åƒç”Ÿæˆ API å¯†é’¥å‡å°è¯•å¤±è´¥")) {
      return new Response(JSON.stringify({ error: { message: err.message, type: "configuration_error", code: "env_config_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
    }
    return new Response(JSON.stringify({ error: { message: "æœåŠ¡å™¨æ„å¤–é”™è¯¯ã€‚", type: "catastrophic_error", code:"fatal_error" } }), { status: 500, headers: { 'Content-Type': 'application/json' } });
  }));
});
